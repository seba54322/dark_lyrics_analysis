{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span></li><li><span><a href=\"#Abrir-el-archivo\" data-toc-modified-id=\"Abrir-el-archivo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Abrir el archivo</a></span></li><li><span><a href=\"#Limpiar-caracteres-persistentes\" data-toc-modified-id=\"Limpiar-caracteres-persistentes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Limpiar caracteres persistentes</a></span></li><li><span><a href=\"#Black-Metal:-Suecia-y-Noruega\" data-toc-modified-id=\"Black-Metal:-Suecia-y-Noruega-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Black Metal: Suecia y Noruega</a></span><ul class=\"toc-item\"><li><span><a href=\"#Datasets\" data-toc-modified-id=\"Datasets-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resumen-de-letras-por-país\" data-toc-modified-id=\"Resumen-de-letras-por-país-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Resumen de letras por país</a></span></li><li><span><a href=\"#Black-metal:-Norway\" data-toc-modified-id=\"Black-metal:-Norway-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Black metal: Norway</a></span></li><li><span><a href=\"#Eliminar-canciones-repetidas\" data-toc-modified-id=\"Eliminar-canciones-repetidas-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Eliminar canciones repetidas</a></span></li><li><span><a href=\"#Construir-corpus\" data-toc-modified-id=\"Construir-corpus-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Construir corpus</a></span></li><li><span><a href=\"#Frequencies\" data-toc-modified-id=\"Frequencies-4.1.5\"><span class=\"toc-item-num\">4.1.5&nbsp;&nbsp;</span>Frequencies</a></span></li></ul></li><li><span><a href=\"#Visualizaciones\" data-toc-modified-id=\"Visualizaciones-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Visualizaciones</a></span><ul class=\"toc-item\"><li><span><a href=\"#Log-Freq-vs-Scaled-F-Score\" data-toc-modified-id=\"Log-Freq-vs-Scaled-F-Score-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Log Freq vs Scaled F-Score</a></span></li><li><span><a href=\"#Log-Frequency-v/s-Log-Odds-Ratio-w/-Uninformative-Prior-(alpha_w=0.01)\" data-toc-modified-id=\"Log-Frequency-v/s-Log-Odds-Ratio-w/-Uninformative-Prior-(alpha_w=0.01)-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Log Frequency v/s Log Odds Ratio w/ Uninformative Prior (alpha_w=0.01)</a></span></li><li><span><a href=\"#Corner-scores\" data-toc-modified-id=\"Corner-scores-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Corner scores</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este Notebook explora letras de Black Metal noruego y Black Metal sueco. Este subgénero tomó relevancia en estos dos países, y se quiere explorar diferencias en el contenido de las letras del mismo género entre estos dos países."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abrir el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import time\n",
    "import scattertext as st\n",
    "from scattertext import produce_scattertext_explorer\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_en_genre_country = pd.read_csv('./from_scratch/df_en_genre_country_24964lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar caracteres persistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_en_genre_country[\"lyric_clean\"] = df_en_genre_country['lyric'].str.replace('[^\\w\\s]|[_]|[\\/]|[\\__]|[&]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_en_genre_country[\"lyric_clean\"] = df_en_genre_country['lyric_clean'].str.replace(' amp | metal ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_en_genre_country[\"song_title_clean\"] = df_en_genre_country['song_title'].str.lstrip('0123456789.- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_en_genre_country.to_csv('./df_en_genre_country_24964lyrics_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_genre_country = pd.read_csv('./df_en_genre_country_24964lyrics_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Metal: Suecia y Noruega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de letras por país"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de letras Black Metal, por país, Noruega, Suecia\n",
    "\n",
    "Norway           2388\n",
    "Sweden           1517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black metal: Norway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['United States','Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_power = df_en_genre_country.loc[df_en_genre_country['genre'] == 'Power Metal']\n",
    "df_en_usa_germany = df_en_power[df_en_power['country'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_usa_germany = pd.DataFrame(df_en_usa_germany)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_en_sweden_norway.shape = (, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar canciones repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_usa_germany = df_en_usa_germany.drop_duplicates(subset=['song_title_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_en_sweden_norway.shape = (3581, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed generating corpus:\n",
      "00:03:16.80\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "corpus = st.CorpusFromPandas(\n",
    "    df_en_usa_germany, category_col='country', text_col='lyric_clean',nlp=nlp).build()\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('Time elapsed generating corpus:')\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time elapsed generating corpus:\n",
    "00:02:01.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 United States\n",
      "['upon',\n",
      " 'within',\n",
      " 'flesh',\n",
      " 'roll',\n",
      " 'cast',\n",
      " 'the earth',\n",
      " 'she',\n",
      " 'her',\n",
      " 'to me',\n",
      " 'rock',\n",
      " 'lives',\n",
      " 'am the',\n",
      " 'across',\n",
      " 'beast',\n",
      " 'we ve',\n",
      " 'must',\n",
      " 'queen',\n",
      " 'watch',\n",
      " 'wicked',\n",
      " 'song',\n",
      " 'as the',\n",
      " 'rage',\n",
      " 'edge',\n",
      " 'above',\n",
      " 'does',\n",
      " 've got',\n",
      " 'control',\n",
      " 'broken',\n",
      " 'children',\n",
      " 'she s',\n",
      " 'man',\n",
      " 'ah',\n",
      " 'sleep',\n",
      " 'yet',\n",
      " 'child',\n",
      " 'thought',\n",
      " 'something',\n",
      " 'past',\n",
      " 'you ve',\n",
      " 'earth',\n",
      " 'as',\n",
      " 'this',\n",
      " 'said',\n",
      " 'kings',\n",
      " 'with a',\n",
      " 'line',\n",
      " 'the pain',\n",
      " 've',\n",
      " 'once',\n",
      " 'walls',\n",
      " 'all that',\n",
      " 'twisted',\n",
      " 'you know',\n",
      " 'these',\n",
      " 'seen',\n",
      " 'rock and',\n",
      " 'through',\n",
      " 'rise',\n",
      " 'ones',\n",
      " 'that you',\n",
      " 'to see',\n",
      " 'yourself',\n",
      " 'that',\n",
      " 'of your',\n",
      " 'soon',\n",
      " 'left',\n",
      " 'taken',\n",
      " 'path',\n",
      " 'things',\n",
      " 'i ve',\n",
      " 'through the',\n",
      " 'that i',\n",
      " 'eyes',\n",
      " 'same',\n",
      " 'with',\n",
      " 'men',\n",
      " 'with the',\n",
      " 'death',\n",
      " 'a man',\n",
      " 'you ca']\n",
      "Top 10 Germany\n",
      "['wanna',\n",
      " 'riding',\n",
      " 'iron',\n",
      " 'na',\n",
      " 'there is',\n",
      " 'on my',\n",
      " 'no more',\n",
      " 'metal',\n",
      " 'till',\n",
      " 'have to',\n",
      " 'gon na',\n",
      " 'better',\n",
      " 'gon',\n",
      " 'after',\n",
      " 'return',\n",
      " 'i wanna',\n",
      " 'ice',\n",
      " 'holy',\n",
      " 'way to',\n",
      " 'break',\n",
      " 'will be',\n",
      " 'sign',\n",
      " 'try to',\n",
      " 'law',\n",
      " 'hey',\n",
      " 'my heart',\n",
      " 'high',\n",
      " 'my way',\n",
      " 'out of',\n",
      " 'stay',\n",
      " 'believe in',\n",
      " 'tears',\n",
      " 'freedom',\n",
      " 'a little',\n",
      " 'do nt',\n",
      " 'under',\n",
      " 'the dark',\n",
      " 'home',\n",
      " 'rules',\n",
      " 'back',\n",
      " 'i m',\n",
      " 'm',\n",
      " 'we will',\n",
      " 'nt know',\n",
      " 'heaven',\n",
      " 'we are',\n",
      " 'be the',\n",
      " 'no way',\n",
      " 's no',\n",
      " 'he s',\n",
      " 'far',\n",
      " 'try',\n",
      " 'oh',\n",
      " 'get',\n",
      " 'back to',\n",
      " 'paradise',\n",
      " 'you will',\n",
      " 'for a',\n",
      " 'fight',\n",
      " 'strong',\n",
      " 'they re',\n",
      " 'going',\n",
      " 'and i',\n",
      " 'is no',\n",
      " 'storm',\n",
      " 'they are',\n",
      " 'up',\n",
      " 'together',\n",
      " 'cause',\n",
      " 'the one',\n",
      " 'pride',\n",
      " 'ai nt',\n",
      " 'land',\n",
      " 'it is',\n",
      " 'eternity',\n",
      " 'win',\n",
      " 'the way',\n",
      " 'free',\n",
      " 'time to',\n",
      " 'gods']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "\n",
    "term_freq_df['United States'] = corpus.get_scaled_f_scores('United States')\n",
    "term_freq_df['Germany'] = corpus.get_scaled_f_scores('Germany')\n",
    "\n",
    "\n",
    "print(\"Top 10 United States\")\n",
    "pprint(list(term_freq_df.sort_values(by='United States', ascending=False).index[:80]))\n",
    "print(\"Top 10 Germany\")\n",
    "pprint(list(term_freq_df.sort_values(by='Germany', ascending=False).index[:80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Freq vs Scaled F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(ar): \n",
    "    return (ar - ar.min()) / (ar.max() - ar.min())\n",
    "\n",
    "def zero_centered_scale(ar):\n",
    "    scores = np.zeros(len(ar))\n",
    "    scores[ar > 0] = scale(ar[ar > 0])\n",
    "    scores[ar < 0] = -scale(-ar[ar < 0])\n",
    "    return (scores + 1) / 2.\n",
    "\n",
    "frequencies_scaled = scale(np.log(term_freq_df.sum(axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed generating scattertext file:\n",
      "00:00:04.22\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='Germany',\n",
    "                                    category_name='Germany',\n",
    "                                    not_category_name='USA',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=800,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=corpus.get_scaled_f_scores('Germany', beta=0.5),\n",
    "                                    scores=corpus.get_scaled_f_scores('Germany', beta=0.5),\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=df_en_usa_germany['band_name'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Scaled F-Score')\n",
    "file_name = './st_usa_germany_01.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('Time elapsed generating scattertext file:')\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time elapsed generating scattertext file:\n",
    "00:00:10.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Frequency v/s Log Odds Ratio w/ Uninformative Prior (alpha_w=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = corpus.get_term_freq_df().rename(columns={'Germany freq': 'y_bl', 'United States freq': 'y_pw'})\n",
    "a_w = 0.01\n",
    "y_i, y_j = freq_df['y_bl'].values, freq_df['y_pw'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i, n_j = y_i.sum(), y_j.sum()\n",
    "a_0 = len(freq_df) * a_w\n",
    "delta_i_j = (  np.log((y_i + a_w) / (n_i + a_0 - y_i - a_w))\n",
    "                 - np.log((y_j + a_w) / (n_j + a_0 - y_j - a_w)))\n",
    "var_delta_i_j = ( 1./(y_i + a_w) + 1./(y_i + a_0 - y_i - a_w)\n",
    "                    + 1./(y_j + a_w) + 1./(n_j + a_0 - n_j - a_w))\n",
    "zeta_i_j = delta_i_j/np.sqrt(var_delta_i_j)\n",
    "max_abs_zeta = max(zeta_i_j.max(), -zeta_i_j.min())\n",
    "zeta_scaled_for_charting = ((((zeta_i_j > 0).astype(float) * (zeta_i_j/max_abs_zeta))*0.5 + 0.5)\n",
    "                            + ((zeta_i_j < 0).astype(float) * (zeta_i_j/max_abs_zeta) * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed generating scattertext file:\n",
      "00:00:04.08\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='Germany',\n",
    "                                    category_name='Germany',\n",
    "                                    not_category_name='USA',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=800,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=zeta_scaled_for_charting,\n",
    "                                    scores=zeta_i_j,\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=df_en_usa_germany['band_name'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Log Odds Ratio w/ Uninformative Prior (alpha_w=0.01)')\n",
    "file_name = './st_usa_germany_02.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('Time elapsed generating scattertext file:')\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed generating scattertext file:\n",
      "00:00:04.34\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "corner_scores = corpus.get_corner_scores('Germany')\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='Germany',\n",
    "                                    category_name='Germany',\n",
    "                                    not_category_name='USA',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=800,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=corner_scores,\n",
    "                                    scores=corner_scores,\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=df_en_usa_germany['song_title_clean'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Corner Scores')\n",
    "file_name = './st_usa_germany_03.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print('Time elapsed generating scattertext file:')\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217.784px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
